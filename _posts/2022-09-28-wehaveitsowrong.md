---
title: "We Have It So Wrong"
date: 2022-09-28
---

A quick thought experiment: Lets say you could take a person, and using a machine, randomize all the neurological wiring in their brain except for three areas, (1) the neurons required for the human vision system, (2) the neurons corresponding to our natural love for sugar, and (3) the neurons pertaining to moving the right hand's pointer and middle fingers. Then, you took that person into a white-wall room, proceeded to show them pictures of cats and dogs, and every time they lifted their pointer finger on a photo of a dog, we gave them a cookie, and every time they lifted their middle finger on a photo of a cat, we gave them a cookie too. The faster they raised the correct finger corresponding to the current image, the larger and sweeter the cookie we gave them.

What do you get? A complete idiot.

My point is, we have it so wrong. We claim to be pursuing AGI, but can anyone really defend the idea that cross entropy is the loss function for humanity? Humans do not learn from a data-equivalent of 10,000 years of training to maximize a loss function. Out brains are not randomized parameters with an arbitrary width and depth. We are beings predisposition with heuristics to assist our biological gradient descent into competency. When we fail and die, we do not automatic restart at our last saved PyTorch checkpoint folder. We are a socially organized species that can learn from others who die and avoid a similar outcome. More importantly, we do not act from strictly linear streams of thought like the forward pass of a neural network. We are capable of thinking and planning outside of formal systems.

I have come across two works (zero shot learning by GPT3 and Reward is Enough by Rich Sutton) that give me hope for general AI, and one of them is not even implemented. We need more.
